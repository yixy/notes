# ILP-指令集并行

**IPL（Instruction-level parallelism，缩写为 ILP）是在基础SISD架构上的不断演进和提升，使用IPL的SISD架构有更好的性能。**

## 1 ILP是什么 ##

计算机处理问题是通过指令实现的,每个指令都是交给CPU执行。在1978年的 Intel 8086 处理器都只能一次执行单指令。这在486或者以前的CPU上是很难想象的，正是因为现代的CPU越来越多的采用了RISC技术，所以才会有ILP。

大约 1985年之后的所有处理器都使用流水线来重登指令的执行过程，以提高性能。由于指令可以并行执行，所以指令之间可能实现的这种重叠称为指令級井行（ILP）。

* 指令层级并行（英语：Instruction-level parallelism，缩写为 ILP），一种平行计算形式，在一个程式运行中，许多指令操作，能在同时间进行。它也是一个测量值，用来计算在一个程式运算中，它有多少个指令能够在同时间运算，称为指令层级并行度。

ILP大体有两种不同开发方法，其中前者的商业应用较为成功

* (1)依靠硬件来帮助动态发现和开发井行：硬件动态调度+多发射+分支预测、推测
* (2)依靠软件技术在编译时静态发现并行：软件静态调度+多发射

使用基于硬件动态方法的处理器，包括 Intel Core 系列，在桌面和服务器市场上占据主导地位。在个人移动设备市场，提高能耗效率通常是一个关键目标，所以设计人员开发较低级别的指令级并行。因此，2011 年，PMD市场的大多数处理器都采用静态方法，我们将会看到 ARM Cortex-A8 中即是如此；不过，未来的处理器（比如新的 ARM Cortex-A9)将采用动态方法。从20世纪80年代开始到最近的 Intel Ttanium 系列，**人们已经无数次尝试基于编译器的积极方法。尽管付出了 无数努力，但除了非常有限的科学应用领城之外，这些方法都没有获得成功。**

## 2 ILP的度量 ##

一个流水化处理器的 CPI（每条指令占用的周期数）值等于基本 CPI 与因为各种停顿而耗费的全部周期之和：

* 流水线 CPI =理想流水线 CPI+ 结构化停顿＋数据骨险停顿 + 控制停顿

理想流水线 CPI可以用来度量能够实现的最佳性能。通过缩短上式右侧各项，可以降低,总流水线 CPI，也就是提高 PC(每个时钟周期执行的指令数）。利用上面的公式，我们可以说明一项技木能够缩小总 CPI 的哪一部分，以此来刻画各种技术的特征。

## 3 基本原理：流水线（Pipeline）与 循环级并行 ##

Intel首次在486芯片中开始使用流水线计算，其原理是：当指令之间不存在相关时，它们在流水线中是可以重叠起来并行执行。

* 流水线（Pipeline）：每个指令的执行需要多个步骤，现代CPU通过流水线的方式允许同时执行多个指令，从而提高功能单元的利用率和系统总吞吐。支持流水线的CPU的IPC(Instructions Per Cycle) 可以达到1，哪怕每条指令实际上需要多个时钟周期才能完成

我们知道指令的执行过程包含以下几个步骤：取指（IF，instruction Fetch）、译码（ID，Instruction Decode）、执行（EXE，Execution）以及写回（WB，Write Back），在早期微架构中我们将这些步骤放在同一个周期内顺序完成，这样设计导致效率很低，当进行取值时，其余部件是空闲的。为了提高各个部件工作效率，流水线技术(Pipeline)就应运而生了。

**基本块**(一段顺序执行代码，除入口外没有其他转入分支，除出口外没有其他转出分支）中可以利用的并行数非常有限。对于典型的 MIPS程序，平均动态分支频率通常介于 15%到 25%之间，也就是说在一对分支之间会执行 3~6条指令。由于这些指令可能相互依赖，所以在基本块中可以开发的重叠数量可能要少于基本块的平均大小。为了真正地提高性能，我们必领跨越多个基本块开发 ILP。提高 ILP的最简单、最常见方法是在循环的各次迭代之间开发并行。这种并行经常被称作**循环级并行**。

**直行代码段可以进行有效的调度，而循环展开是一种增大直行代码受规模的简单有效方法。**这种转换在名种处理器上都非常有用，从我们前面己经研究过的简单流水线，到名发射超标量，再到本章后面要研究的 VLTW。

实践中，这一过程必须采用系统方式，由编译器或硬件来完成。为了获得最终展开后的代码，必须进行如下快策和变换。

1. 确认循环选代不相关（循环维护代码除外），判定展开循环是有用的。
2. 使用不同奇存器，以避免由于不同运算使用相同寄存器而施加的非必要约東（比如，名称相关)。
3. 去除多余的测试和分支指令，并调整循环终止与迭代代码。
4. 观察不同迭代中的载人与存储指令互不相关，判定展开后的循环中的载人和存储指今可以交换位置。这一变换需要分析存储器地址，查明它们没有引用同一地址。
5. 对代码进行调度，保留任何必要相关，以得到与原代码相同的结果。

要进行所有这些变换，最关键的要求就是要理解指令之间的相关依赖关系，而且要知道在这些给定关系下如何改变指令或调整指令的顺序。

注意，除了循环展开外，IPL还会采用**分支预测和推测等机制**。

## 4 编译器机制：静态调度 ##

编译器静态展开循环。

为使流水线保持满载，必领找出可以在流水线中重叠的不相关指令序列，充分开发指令并行。为了避免流水线停頓，必须特相关指令与源指令的执行隔开一定的时间周期，这一间隔应当等于源指令的流水线延迟。编译器执行这种调度的能力既依赖于程序中可用 ILP 的数目，也依赖于流水线中功能单元的延迟。

## 5 硬件机制：动态调度（乱序执行） ##

硬件动态展开循环。

除非是流水线中的已有指令与要提取的指令之间存在数据相关，而且无法通过旁路或转发来隐嫩这一数据相关，吞则，简单的静态调度流水线就会提取一条指令并发射出去。(转发逻辑可以减少实际流水线延迟，所以某些特定的相关不会导致冒险。如果存在不能隐藏的数据相关，那些冒险检测软件会从使用该结果的指令开始，将流水线置于停顿状态。在清除这一相关之前，不会提取和发射新的指令。比如，当前后两条指令存在依赖关系时，流水线需要停顿：

```
x=1+2
y = x*3
```

CPU通过指令的乱序执行可以充分挖掘流水线的指令集并行潜能。指令以不违反数据依赖性的任何顺序执行。硬件会重新安排指令的执行顺序以减少停顿，并同时保持数据流和异常行为。动态调度有几个优点。第一，它允许针对—种流水线编译的代码在不同流水线上高效执行，不需要在使用不同微体系结构时重新进行编译，并拥有多个二进制文件。在当今的计算环境中，大多数软件都来自第三方，而且是以二进制文件形式分发的，这一优势尤其明显。第二，在某些情况下，在编译代码时还不能知道相关性，利用动态调度可以处理某些此类情况；比如，这些相关可能涉及存储器引用或者与数据有关的分支，或者，它们可能源自使用动态链接或动态分发的现代编程环境。第三，地可能是最重要的一个个优点，它允许处理器容忍一些预料之外的延迟，比如缓存缺失，它可以在等待解决缺失问题时执行其他代码。

## 6 硬件机制：动态分支预测(Dynamic Branch Prediction) ##

由于需要通过分 支冒险 和停顿来实施控制相关，所以分支会伤害流水线性能。循环展开是降低分支冒险的一种方法，我们还可以通过预测分支的行为方式来降低分支的性能损失。

* 动态分支预测：用于避免停顿以解决控制依赖项。注意，当分支预测错误时，清除取到的指令，并从另一个分支目标取指令执行。

带流水线的CPU需要每个时钟发射1条指令，但只有分支指令执行结束后才能确定下条指令是什么，这就导致流水线停顿(Pipeline Stall)。为避免分支指令导致的流水线停顿，一种对策是分支预测，即在发射分支指令之后，马上预测下条指令的地址并发射，如果分支指令执行结束后发现预测错误，则撤销之前的操作取正确的指令重新发射。这里预测失败导致的撤销开销，叫分支预测惩罚(Mispredict Penalty)，由于现代系统的分支预测正确率很高，摊还后的惩罚开销往往可以接受。动态分支预测是基于分支指令历史进行的，现代CPU的预测正确率在大部分场合可以高达95%以上；相对的，静态分支预测是基于固定分支选择策略、源码中的Hint，或根据编译器的得到的Profile信息来完成的。

常见的分支预测实现。

1. 分支预测表（1bit）：根据上次跳转情况预测下次是否跳转。比如，这次跳转了，就预测下次也跳转。
2. 2bit分支预测表：使用状态机判断，根据上次跳转情况预测下次是否跳转，能够容忍一次条件不符合。比如，这次跳转了，就预测下次也跳转；如果这次没跳转，则容忍一次，还是预测下次也跳转，如果下下次还是没跳转，则下下下次预测不跳转。
3. 相关(m,n)分支预测表
4. 竞赛预测器：多个策略混合，通过机制判断哪个好用用哪个。


## 7 硬件机制：推断执行(Speculative Execution) ##

我们尝试开发更多指令级并行时，控制相关的维护就会成为一项不断加重的负扭。分支预测减少了由于分支导致的直接停顿，但对于每个时钟周期要执行多条指令的处理器来说，仅正确地预测分支可能不足以生成期望数量的指令级并行。宽发射处理器可能需要每个时钟周期执行一个分支才能维持最高性能。因此，要开发更多并行，需要我们克服控制相关的局限性。

通过预测分支的输出，然后在假定猜测正确的前提下执行程序，可以克服控制相关问题。这种机制对采用动态调度的分支预测进行了一种虽细微但很重要的扩展。具体来说，通过推测我们捉取、发射和执行指令，就好像分支预测总是正确的；而动态调度只是提取和发射这些指令。当然，我们需要一些机制来处理推测错误的情景。

* 推断（speculation）：检查猜测是否正确，如果错误则需要rollback。推测执行结果要等到指令状态处于非前瞻状态（即分支确定）时，才能确定为最终结果提交返回。

推测执行的常用形式是控制流推测，其中在确定控制流指令的目标之前执行经过控制流指令（例如，分支）的指令。已经提出并正在使用其他几种形式的推测执行，包括由以下方面驱动的推测执行： 价值预测, 记忆依赖预测 和 缓存等待时间预测。





支持动态分支预测和乱序执行的处理器，需要保留一个重排序缓冲区(Reorder Buffer)，用来对乱序执行的指令进行顺序提交(In-Order Commit)。重排序缓冲区为推断失败时的撤销提供了解决方案，只需要清空分支指令后的所有指令即可。另外，顺序提交也为精确异常(Precise Exception)提供了基础，这是操作系统中断和缺页故障(Page Fault)处理的关键。推断执行的指导思想是“加速大概率事件”

## 8 硬件机制：多发射/超标量（superscalar）##

前面介绍的编译器或硬件机制使 CPI 逼近到达理想值 1。为了进一步提高性能，我们希望将 CPI降低至小于 1，但如果每个时钟周期仅发射一条指令，那 CPI 是不可能降低到小于 1的。既然流水线技术可以实现不间断取指、解码、执行、写回，那么可以同时让几条流水线一起工作，这就是超标量技术。

> 为更好的利用富裕的功能单元，CPU希望IPC能够超过1，这就要求每个时钟发射多条指令。支持超标量的处理器，需要处理同时发射的多条指令间的数据依赖关系，这个复杂性限制了动态发射窗口的大小。与之相对的是静态多发射，即由编译器或程序员往一个发射包(Issue Packet)中填充多条无关指令，然后同时发射和执行，典型的例子是超长指令字(Very Long Instruction Word)体系结构

* 多发射处理器（也称为超标量处理器）：超标量是指在CPU中有一条以上的流水线，并且每时钟周期内可以完成一条以上的指令，这种设计就叫超标量技术。 其实质是以空间换取时间。其目标就是允许在一个时钟周期中发射多条指令。

多发射处理器主要有以下 3类。

* 静态调度超标量处理器：每个时钟发射不同数目的指令，采用静态调度，循序执行。
* 动态调度超标量处理器：每个时钟发射不同数目的指令，采用动态调度，乱序执行。
* VLIW（超长指令字）处理器：VLIW 处理器每个时钟周期发射固定数目的指令，这些指令可以设登为两种格式之一。一种格式是一个长指令；另一种是一个固定的指令包，指令之间具有一定的并行度，由指令显式表示出来。VLIW 处理器由编译器进行静态调度。

超长指令字(VLIW)处理器是超标量处理器的一种特殊情况。Inatel 和HIP 在创建 IA-64 体系结构时，它们还將这种体系结构命名为 EPIC（显式并行指令计算机）。尽管静态调度超标量处理器在每个周期内发射的指令数是可变的，而不是固定的，但它们在概念上实际与 VLIW 更接近一些，这是因为这两种方法都依靠编译器为处理器调度代码。由于静态调度超标量的收益会随着发射宽度的增长而逐渐减少，所以静态调度超标量主要用手发射宽度较窄的情况，通常仅有两条指令。超过这一宽度之后，大多数设计人员选择实现VLTW 或动态调度超标量。由于两者的硬件要求和所需要的编译器技术是类似的。
