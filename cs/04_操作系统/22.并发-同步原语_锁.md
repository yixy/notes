# 并发-同步原语:锁

https://cloud.tencent.com/developer/article/1176832

我们希望原子式执行一系列指令, 但由于单处理器上的中断 (或者多个线程在多处理器上并发执行) , 我们做不到。锁(lock) 可以直接解决这一问题。程序员在源代码中加锁,放在临界区周围,保证临界区能够像单条原子指令一样执行。

我们需要硬件和操作系统的帮助来实现一个可用的锁。近些年来,各种计算机体系结构的指令集都增加了一些不同的硬件原语,我们不研究这些指令是如何实现的(毕竟,这是计算机体系结构课程的主题) ,只研究如何使用它们来实现像锁这样的互斥原语。

> POSIX 库将锁称为互斥量(mutex) ,因为它被用来提供线程之间的互斥。即当一个线程在临界区,它能够阻止其他线程进入直到本线程离开临界区。

## 1 如何评价锁的效果

在讨论硬件和OS的支持之前，我们先来看看如何评价锁的好坏。

第一是锁是否能完成它的基本任务,即**提供互斥(mutual exclusion) ,锁是否有效**,能够阻止多个线程进入临界区?

第二是**公平性(fairness)**：当锁可用时,是否每一个竞争线程有公平的机会抢到锁？是否存在饿死（starve）状态？

第三是**性能(performance)**：使用锁之后增加的时间开销。有几种场景需要考虑。一种是没有竞争的情况,即只有一个线程抢锁、释放锁的开支如何?另外一种是一个 CPU 上多个线程竞争,性能如何?最后一种是多个 CPU、多个线程竞争时的性能。

## 2 锁的硬件实现

###### 2.1 关闭中断（单处理器操作系统内部使用）

最早提供的互斥解决方案之一,就是在临界区关闭中断。这个解决方案是为单处理器系统开发的，并且基于以下原因,只在很有限的情况下用关闭中断来实现互斥原语。例如,在某些情况下操作系统本身会采用屏蔽中断的方式,保证访问自己数据结构的原子性,或至少避免某些复杂的中断处理情况。这种用法是可行的,因为在操作系统内部不存在信任问题,它总是信任自己可以执行特权操作。

首先,这种方法要求我们允许所有调用线程执行特权操作(打开关闭中断) ,即我们需要信任这种机制不会被滥用。第二,这种方案不支持多处理器。如果多个线程运行在不同的 CPU 上,每个线程都试图进入同一个临界区,关闭中断也没有作用。线程可以运行在其他处理器上,因此能够进入临界区。多处理器已经很普遍了,我们的通用解决方案需要更好一些。第三,关闭中断导致中断丢失,可能会导致严重的系统问题。最后一个不太重要的原因就是效率低。与正常指令执行相比,现代 CPU 对于关闭和打开中断的代码执行得较慢。 

###### 2.2 总线锁定

所谓总线锁就是使用处理器提供的一个LOCLK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。

总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其它处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。

###### 2.3 缓存锁定（依赖缓存一致性协议实现）

频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”是指如果共享内存如果被换存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效。

但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时，则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Intel486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。

## 3 自旋锁机制

atomi- exchange、compare-and-exchange 、链接的加载和条件式存储指令、fetch-and-add等锁实现均为自旋锁。 **自旋锁(spin lock)** 是最简单的一种锁,一直自旋等待(spin-waiting),不停地检查标志的值，利用 CPU 周期,直到锁可用。在单处理器上,需要抢占式的调度器(preemptive scheduler,即不断通过时钟中断一个线程,运行其他线程) 。否则,自旋锁在单 CPU 上无法使用,因为一个自旋的线程永远不会放弃 CPU。

首先考虑锁最重要的一点是正确性 (correctness) : 能够互斥吗?答案是可以的:**自旋锁一次只允许一个线程进入临界区。**因此,这是正确的锁。 

* 如何解决原子性问题：程序会根据当前处理器的类型来决定是否为相关指令指令（如cmpxchg）添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。（lock指令即真实的硬件锁操作，比如缓存锁或总线锁。）

下一个标准是公平性(fairness) 。自旋锁对于等待线程的公平性如何呢?能够保证一个等待线程会进入临界区吗?答案是自旋锁不提供任何公平性保证。实际上,大部分自旋的线程在竞争条件下可能会永远自旋，此时自旋锁没有公平性,可能会导致饿死。** fetch-and-add实现的ticket锁不同于之前的方法:本方法能够保证所有线程都能抢到锁。**只要一个线程获得了 ticket 值,它最终会被调度，之前的方法则不会保证。

自旋锁的性能问题主要是线程在等待已经被持有的锁时,采用了**自旋等待(spin-waiting)的技术,自旋等待在等待其他线程释放锁的时候会浪费时间。**首先,考虑线程在单处理器上竞争锁的情况。然后,考虑这些线程跨多个处理器。 对于自旋锁,在单 CPU 的情况下,性能开销相当大。假设一个线程持有锁进入临界区时被抢占。调度器可能会运行其他每一个线程(假设有 N−1 个这种线程) 。而其他线程都在竞争锁,都会在放弃 CPU 之前,自旋一个时间片,浪费 CPU 周期。 但是,在多 CPU 上,自旋锁性能不错(如果线程数大致等于 CPU 数) 。假设线程 A 在CPU 1,线程 B 在 CPU 2 竞争同一个锁。线程 A(CPU 1)占有锁时,线程 B 竞争锁就会自旋(在 CPU 2 上) 。然而,临界区一般都很短,因此很快锁就可用,然后线程 B 获得锁。自旋等待其他处理器上的锁,并没有浪费很多 CPU 周期,因此效果不错。可以看到，在单处理器上,一个等待线程等待的目标线程甚至无法运行(至少在上下文切换之前)，我们要开发出更成熟的解决方案,也应该考虑避免这种浪费。

###### 3.1 atomic exchange

最简单的自旋锁硬件支持是测试并设置指令 (test-and-set instruction) , 也叫作原子交换 (atomic exchange) 。这个更强大的指令在不同硬件架构上有不同的名字: 在 SPARC 上,这个指令叫 ldstub(load/store unsigned byte,加载/保存无符号字节) ;在 x86 上,是 xchg (atomic exchange,原子交换)指令。但它们基本上在不同的平台上做同样的事,通常称为测试并设置指令(test-and-set) 。

atomic exchange的伪代码：

```
int TestAndSet(int *old_ptr, int new) {
	int old = *old_ptr; // fetch old value at old_ptr
	*old_ptr = new;    // store 'new' into old_ptr
	return old;        // return the old value
}
```

atomic exchange实现锁的伪代码：


```
typedef struct lock_t {
	int flag;
} lock_t;
	
void init(lock_t *lock) {
	// 0 indicates that lock is available, 1 that it is held
	lock->flag = 0;
}
	
void lock(lock_t *lock) {
	while (TestAndSet(&lock->flag, 1) == 1){
		   ; // spin-wait (do nothing)
	}
} 

void unlock(lock_t *lock) {
	lock->flag = 0;
}

```

###### 3.2 CAS（compare-and-swap）/ compare-and-exchange

某些系统提供了另一个硬件原语, 即比较并交换指令 (SPARC 系统中是CAS即 compare-and-swap, x86 系统是 compare-and-exchange) 。 

```
int CompareAndSwap(int *ptr, int expected, int new) {
	int actual = *ptr;
	if (actual == expected){
		*ptr = new;
	}
	return actual;
}
```

比较并交换的基本思路是检测 ptr 指向的值是否和 expected 相等;如果是,更新 ptr 所指的值为新值。否则,什么也不做。不论哪种情况,都返回该内存地址的旧值,让调用者能够知道执行是否成功。

```
void lock(lock_t *lock) {
	while (CompareAndSwap(&lock->flag, 0, 1) == 1){
		; // spin
	}
}
```

最后,你可能会发现,比较并交换指令比测试并设置更强大。当我们在将来简单探讨无等待同步(wait-free synchronization)时,会用到这条指令的强大之处(例如Java中通过CAS实现乐观锁)。然而,如果只用它实现一个简单的自旋锁,它的行为等价于上面分析的自旋锁。

###### 3.3 链接的加载和条件式存储指令

一些平台提供了实现临界区的一对指令。例如 MIPS 架构中,链接的加载(load-linked)和条件式存储(store-conditional)可以用来配合使用,实现其他并发结构。

```
int LoadLinked(int *ptr) {
	return *ptr;
}
int StoreConditional(int *ptr, int value) {
	if (no one has updated *ptr since the LoadLinked to this address) {
		*ptr = value;
		return 1; // success! 
	} else {
		return 0; // failed to update 
} 
```

```
void lock(lock_t *lock) {
	while (1) {
		while (LoadLinked(&lock->flag) == 1){
			; // spin until it's zero
	}
	if (StoreConditional(&lock->flag, 1) == 1){
		return; // if set-it-to-1 was a success: all done
		// otherwise: try it all over again
	}  
} 

void unlock(lock_t *lock) { 
	lock->flag = 0;
}
```

等价于

```
void lock(lock_t *lock) {
	while (LoadLinked(&lock->flag)||!StoreConditional(&lock->flag, 1)) {
		; // spin 
	}
}
```

###### 3.4 fetch-and-add

最后一个硬件原语是获取并增加(fetch-and-add)指令,它能原子地返回特定地址的旧值,并且让该值自增一。获取并增加的 C 语言伪代码如下:

```
int FetchAndAdd(int *ptr) {
	int old = *ptr;
	*ptr = old + 1;
	return old;
}
typedef struct  lock_t {
	int ticket;
	int turn;
} lock_t; 
void lock_init(lock_t *lock) {
	lock->ticket = 0;
	lock->turn   = 0;
	} 
void lock(lock_t *lock) {
	int myturn = FetchAndAdd(&lock->ticket);
	while (lock->turn != myturn){
		; // spin 15 
	}
} 
void unlock(lock_t *lock) { 
	FetchAndAdd(&lock->turn); 
}
```

不是用一个值,这个解决方案使用了 ticket 和 turn 变量来构建锁。基本操作也很简单: 如果线程希望获取锁,首先对一个 ticket 值执行一个原子的获取并相加指令。这个值作为该线程的 “turn” (顺位, 即 myturn) 。 根据全局共享的 lock->turn 变量, 当某一个线程的 (myturn == turn)时,则轮到这个线程进入临界区。unlock 则是增加 turn,从而下一个等待线程可以进入临界区。不同于之前的方法:本方法能够保证所有线程都能抢到锁。只要一个线程获得了 ticket 值,它最终会被调度。之前的方法则不会保证。比如基于测试并设置的方法,一个线程有可能一直自旋,即使其他线程在获取和释放锁。

## 4 操作系统的支持：使用队列-休眠替代自旋

我们已经实现了有效、公平(通过 自旋-ticket 实现)的锁。但是,问题仍然存在:如果临界区的线程发生上下文切换,其他线程只能一直自旋,等待被中断的(持有锁的)进程重新运行。有什么好办法?一种简单友好的方法就是,在要自旋的时候,放弃 CPU。

###### 4.1 使用yield原语（上下文切换成本依然高，并且可能存在饿死）

我们假定操作系统提供原语 yield(),线程可以调用它主动放弃 CPU, 让其他线程运行。线程可以处于 3 种状态之一(运行、就绪和阻塞) 。yield()系统调用能够让运行(running)态变为就绪(ready)态,从而允许其他线程运行。因此,让出线程本质上取消调度(deschedules)了它自己。

考虑在单 CPU 上运行两个线程。 在这个例子中, 基于 yield 的方法十分有效。 一个线程调用 lock(),发现锁被占用时,让出 CPU,另外一个线程运行,完成临界区。在这个简单的例子中,让出方法工作得非常好。现在来考虑许多线程(例如 100 个)反复竞争一把锁的情况。在这种情况下,一个线程持有锁,在释放锁之前被抢占,其他 99 个线程分别调用 lock(),发现锁被抢占,然后让出 CPU。假定采用某种轮转调度程序,这 99 个线程会一直处于运行—让出这种模式,直到持有锁的线程再次运行。虽然比原来的浪费 99 个时间片的自旋方案要好,但这种方法仍然成本很高,上下文切换的成本是实实在在的,因此浪费很大。 更糟的是,我们还没有考虑饿死的问题。一个线程可能一直处于让出的循环,而其他线程反复进出临界区。很显然,我们需要一种方法来解决这个问题。

###### 4.2 使用队列:休眠替代自旋

我们必须显式地施加某种控制,决定锁释放时,谁能抢到锁。为了做到这一点, 我们需要操作系统的更多支持,并需要一个队列来保存等待锁的线程。

以Solaris为例，它提供了三个系统调用:park()能够让调用线程休眠,unpark(threadID)则会唤醒 threadID 标识的线程。可以用这两个调用来实现锁,让调用者在获取不到锁时睡眠,在锁可用时被唤醒。第三个系统调用 setpark()，通过 setpark(),一个线程表明自己马上要 park。如果刚好另一个线程被调度,并且调用了 unpark,那么后续的 park 调用就会直接返回,而不是一直睡眠。

其他操作系统也提供了类似的支持,但细节不同。 例如,Linux 提供了 futex（Fast Userspace muTexes）,它类似于 Solaris 的接口,但提供了更多内核功能。Futex将内核中的对象提到用户空间上，在用户空间上对Futex体进行操作，判断是否存在竞争，再根据是否存在竞争来判断是否要陷入内核。如果不存在竞争就不陷入内核，直接进入互斥区；如果存在竞争则委托操作系统进行FUTEX_WAIT或FUTEX_WAKE等操作，这样就省去了传统Unix进程间同步机制的部分系统调用开销。具体来说, 每个 futex 都关联一个特定的物理内存位置,也有一个事先建好的内核队列。调用者通过futex 调用来睡眠或者唤醒。具体来说,有两个调用。调用 futex_wait(address, expected)时,如果 address 处的值等于expected,就会让调线程睡眠。否则,调用立刻返回。调用 futex_wake(address)唤醒等待队列中的一个线程。

> futex 设计思想其实不难理解，在传统的Unix系统中，System V IPC(inter process communication)，如 semaphores, msgqueues, sockets还有文件锁机制(flock())等进程间同步机制都是对一个内核对象操作来完成的，这个内核对象对要同步的进程都是可见的，其提供了共享 的状态信息和原子操作。当进程间要同步的时候必须要通过系统调用(如semop())在内核中完成。可是经研究发现，很多同步是无竞争的，即某个进程进入 互斥区，到再从某个互斥区出来这段时间，常常是没有进程也要进这个互斥区或者请求同一同步变量的。但是在这种情况下，这个进程也要陷入内核去看看有没有人 和它竞争，退出的时侯还要陷入内核去看看有没有进程等待在同一同步变量上。这些不必要的系统调用(或者说内核陷入)造成了大量的性能开销。为了解决这个问 题，Futex就应运而生，Futex是一种用户态和内核态混合的同步机制。首先，同步的进程间通过mmap共享一段内存，futex变量就位于这段共享 的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex,而不 用再执行系统调用了。当通过访问futex变量告诉进程有竞争发生，则还是得执行系统调用去完成相应的处理(wait 或者 wake up)。简单的说，futex就是通过在用户态的检查，（motivation）如果了解到没有竞争就不用陷入内核了，大大提高了low-contention时候的效率。 Linux从2.5.7开始支持Futex。

## 5 两阶段锁:一定的自旋后进入队列休眠

Linux 采用的是一种古老的锁方案,多年来不断被采用,可以追溯到 20 世纪 60 年代早期的 Dahm 锁,现在也称为**两阶段锁(two-phase lock) **。两阶段锁意识到自旋可能很有用,尤其是在很快就要释放锁的场景。因此,两阶段锁的第一阶段会先自旋一段时间,希望它可以获取锁。 但是,如果第一个自旋阶段没有获得锁,第二阶段调用者会睡眠,直到锁可用。上文的 Linux 锁就是这种锁,不过只自旋一次;更常见的方式是在循环中自旋固定的次数,然后使用 futex 睡眠。 两阶段锁是又一个杂合(hybrid)方案的例子,即结合两种好想法得到更好的想法。当然,硬件环境、线程数、其他负载等这些因素,都会影响锁的效果。事情总是这样,让单个通用目标的锁,在所有可能的场景下都很好,这是巨大的挑战。
