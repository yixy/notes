# 体系结构的发展2-RISC和ILP&Cache #

1970s(20世纪70年代后期）-2003可以称为是体系结构发展的黄金时代。

20世纪70年代后期开始，计算机性能的增长速度加上大规模生产的微处理器的成本优势，导致**越来越多的计算机业务以微处理器为基础**，80年代，**RSIC计算机出现，指令集并行技术发展迅速**，体系结构与组织方式的发展一起促成了计算机性能以超过 50%的年增长率特续增长 17年（1986-2003），这一速率在计算机行业内是空前的。

<img src="growthinprocessorperformance.PNG" alt="100%" width="100%">

## 1 RISC计算机的出现 ##

###### CISC架构 ######

早期，为降低手工编写机器码的难度，指令集设计的比较复杂，为和后面的RISC区分，这种ISA被称为CISC架构。

* 复杂指令集计算机”(CISC)：单指令通常能够执行多个底层基本操作，比如：从内存中加载数据、执行一次算术运算．然后再将运算结果写回主存），或者是条指令内可以混杂多种不同的寻址模式。

###### 背景1：必须降低微处理器原本的复杂度 ######

20世纪70年代后期开始，计算机性能的增长速度加上大规模生产的微处理器的成本优势，导致越来越多的计算机业务以微处理器为基础。几乎就在同时，**微处理器开始比内存运行得更快。**即便是在七十年代末，人们也已经认识到这种不一致性至少会在下一个十年继续增加，到时微处理器将会比内存的速度快上百倍。很明显，需要有更多寄存器（以及后来的缓存）来支持更高频率的操作。**为此，必须降低微处理器原本的复杂度，以节省出空间给新增的寄存器和缓存。**

###### 背景2：编译器和操作系统的发展带来了契机和需求 ######

与此同时，计算机市场的两个重大变化也使新体系结构更容易在商业上获得成功。第一个重大变化是人们**几乎不再使用汇编语言进行编程**，从而降低了对目标代码兼容性的要求。第二个重大变化是**出现了独立于厂商的标准化操作系统（比如 UNIX 和它的克隆版本Linux )**，降低了引人新体系结构的成本和风险。

###### 背景3：CISC本身的劣势 ######

20世纪70年代后期，业界发现已有的CISC指令系统面临一些难以克服的问题：1）指令使用频度的问题：大约只有20%的指令会被反复使用，占整个程序代码的80%；2）CISC指令系统复杂，增加研制时间和成本，容易出错；3）不定长的指令不规整，不利于运用先进计算机体系结构技术来提高系统性能。

> 1970年代后期，IBM（以及其它类似企业组织）的研究人员显示，大多数正交寻址模式基本上已被程序员所忽略。这是编译器的使用逐渐增多而汇编语言的使用相对减少所导致的。值得注意的是，由于编写编译器的难度很大，当时编译器并不能充分利用CISC处理器所提供的各种特性。尽管如此，广泛应用编译器的趋势已然很明显，从而使得正交寻址模式变得更加无用。这些复杂操作很少被使用。

> 事实上，相比用更精简的一系列指令来完成同一个任务，用单一复杂指令甚至会更慢。这看上去有些自相矛盾，却源自于微处理器设计者所花的时间和精力：设计者一般没有时间去调整每一条可能被用到的指令，通常他们只优化那些常用的指令。

###### RISC架构 ######

正是由于这些变化，人们才有可能在 20 世纪 80 年代早期成功地开发了一组指令更为简单的新体系结构-RISC(精简指令集计算机）体系结构。1981年，图灵奖得主David Patterson发表了开创性的论文 《The Case for a ReducedInstruction Set Computer》 首次提出了RISC这种指令集设计方法，由此开创了RISC指令集大发展的时代。后面新出现的指令集基本都是RISC风格的指令集： MIPS、 PowerPC、ARM、RISC-V等等。RISC被认为是通用ISA设计的最好原则。

* 精简指令集计算机”(RISC):是一种执行较少类型、高度优化的计算机指令的微处理器架构。它主要是相对于CISC架构而言的。

基于 RISC的计算机抬高了性能指标，过去的体系结构要么快速跟上,要么就被淘汰。DigitalEquipment Vax 未能跟上时代的脚步，所以 RISC体系结构替代。**Intel则接受挑战，主要是在内部将 80x86指令转换为类似于 RISC 的指令，使它能够采用许多最初由 RISC 设计倡导的新技术。**20世纪 90 年代后期，品体管的数目 飞速增长，所以在转换更复杂 ×86体系结构时的硬件开销可以忽略不计。**在低端应用中，比如在手机中，由于x86转换开销所带来的功耗与硅面积成本，促使一种 RISC 体系结构逐渐成为主流，这就是 ARM。**

不过RISC也有它的缺点。当需要一系列指令用来完成非常简单的程序时，从存储器读入的指令总数会变多，因此也需要更多时间。在当时的工业和设计领域，对RISC的性能优劣有大量持续不断的争论。

> Apple Mac 进行过两次CPU换“芯”。1）2006年，PowerPC（RISC）移植到 Intel X86（CISC）：X86实现了在CPU内部将 80x86指令转换为类似于 RISC 的指令，性能和技术上与RISC已基无区别，而PowerPC散热存在问题，所以乔布斯决定更换ISA。除了X86版本的OS外，Apple提供了编译器，原来的PowerPC架构程序仅需重新编译即可在X86上运行。2）2022年，Intel X86（CISC）迁移到 自研的A系列处理器-ARM（RISC）：考虑功耗

###### VLIW架构 ######

VLIW架构是由Josh Fisher在20世纪80年代早期提出的，其主要思想是将多个相互无依赖的指令放到一条超长的指令字中，以此来提高处理器指令间执行的并行度。由于在一条指令中封装了多个并行操作，其指令的长度比RISC或CISC的指令要长，因此起名为超长指令字架构。

* 超长指令字（VLIW：Very long instruction word）：将多个相互无依赖的指令放到一条超长的指令字中，以此来提高处理器指令间执行的并行度。

**在32位向64位CPU升级时，Intel推出了IA64，并由此制造出了Itanium系列处理器。AMD则对x86进行了扩展，加入了64位寻址和64位寄存器，最终出来的架构，被称为AMD64，成为了64位版本的x86_64处理器的标准。IA64项目并不算得上成功，现如今基本被放弃了，Intel最终也转向了AMD64。**

Intel Itanium是业界最后一个款通用VLIW处理器，IA-64架构是Intel规划的32位x86的下一代架构，Intel Itanium（IA64）放弃了超标量导致的复杂硬件（以及难以预测的 performance），想把这些工作放到编译器上，然后通过更加全局的优化和指令依赖分析来超过超标量 cpu。但实际上碰到了三个问题：指令集升级困难、无法充分利用cache、不兼容 x86_32 位指令集。最终导致在与AMD的64位架构x86_64竞争中最终失败而告终。但在通用计算领域VLIW是失败的，复杂的VLIW结构接近顺序超标量结构，但在大型复杂应用中不存在优势。VIIW在嵌入式DSP市场比较成功：简单的VLIW，分支简单、没有Cache，小程序。

Itanium失败的原因：

1）指令集升级困难：安腾的具体思路是让编译器自动判别依赖关系并产生一个个指令包，每个包内的指令不存在依赖关系。所以指令集一公布，要想改就困难了。例如每 个VLIW指令包是包着三个RISC指令的，如果若干年后做出了能并行执行六个指令的芯片，那它不能一起执行两个VLIW指令吗，因为这两个VLIW指令很可能有依赖关系。只有两个解决办法：其一是一次运行三条指令（即使我的机器有能力执行六个宽度），所以程序执行效率只有一半；其二是要求每有新一代的芯片出现，所有 程序都要重新编译才能完全发挥芯片设计的理论效能。这是让人无法忍受的一件事——难道今后软件发布出来，要为各个指令宽度的Itanium各做一个版本吗?

2）无法充分利用cache：当处理器发出内存访问请求时，会先查看Cache内是否有请求资料。如果命中，则不需访问内存直接返回该数据；如果不存在，则要先把内存中的相应数据加载入Cache，再将其返回处理器，这需要更长的等待时间。对于一个可以乱序执行的处理器而言，如果某 条数据的结果不在Cache里，可以动态调度，先执行别的语句，从内存里取出，再执行这条语句。而安腾重新采用了有序执行技术，Itanium把可以并发的程序指令捆在一个包中，如果这个包中所需要的变量还在内存里，那处理器就什么都干不了，只能等从内存数据搬到Cache中。所以，Itanium的执行效率不会好于乱序执行的处理器。

3）不兼容32位实现。不同于AMD64位对32位架构的兼容处理，Itanium（IA64）不兼容32位实现，这也是它的很大劣势。

## 2 指令集并行（ILP，Instruction-Level Parallelism）与Cache ##

设计人员在设计 RISC 计算机时，将主要精力投注在ILP（Instruction-Level Parallelism）这种关键的性能技术上，即**指令级并行的开发（最初是通过流水线，后来是通过多指令发射）和缓存的使用（最初采用一些很简单的形式，后来使用了更为复杂的组织与优化方式)。**
