# 体系结构的发展3-DLP&TLP&RLP

从 2003 年开始，由于风冷芯片最大功耗和无法有效地开发更多指令级并行这两大瓶颈，单处理器的性能提高速度下降到每年不足 22%。事实上，intel 在 2004年取消了 自己的高性能单核处理器项目，转而和其他公司一起宣布：**为了获得更高性能的处理器，应当提高一个芯片上集成的核心数目，而不是加快单核处理器的速度。**这是一个标志着历史性转折的里程碑信号，**处理器性能的提高从单纯依赖指令级并行(ILP)转向数据级并行（DLP）和线程级并行 （TLP）。**

>1974 年，Robert Dennard 观察到，即使由于每个晶体管的尺寸较小而增加了晶体管的数量，芯片消耗的能量对于给定的硅面积也是恒定的。简而言之：随着给定空间内能够容纳的晶体管的数量不断增加，计算机的速度会越来越快，价格会越来越低。Dennard 缩放在 2004 年左右结束，因为电流和电压无法继续下降并仍然保持集成电路的可靠性。

>1965 年，戈登·摩尔 (Gordon Moore) 著名地预测每个芯片的晶体管数量将每年翻一番，并在 1975 年修改为每两年一次。这一预测持续了大约 50 年，目前已不再成立。


## 1 DLP & TLP & RLP ##


编译器和硬件都是隐式开发 ILP 的，不会引起程序员的注意，而 DLP、TLP和RLP 则是显式并行的，需要调整应用程序的结构才能开发实现并行。在某些情况下，这一调整比较容易，但在大多数情况下，它会成为程序员的主要新增负担。

线程的概念就是程序的执行序，每个执行序有执行上下文需要保存。

* ILP – instruction level parallelism (pipelining)
* DLP – data level parallelism (pipelined arithmetic units, loop unrolling)
* TLP – thread-level processing (using multiple processors/cores)
* RLP – request-level processing (multiple processors/cores plus OS help)

矢量计算机（Vector Computer）：矢量处理技术也在视频游戏控制台硬件和图形加速器中运行。

人工智能加速器（英語：AI accelerator）是一类专用于人工智能（特别是人工神经网络、机器视觉、机器学习等）硬件加速的微处理器或计算系统。

DSA（Domain Specific Architecture，特定领域架构）。意思是说，未来需要面向不同的场景，需要根据场景的特点，去定制芯片。

## 2 CA在不同时代的研究侧重点 ##


| Ages  | Key Research Scopes                       | Sample Computers            |
|-------|-------------------------------------------|-----------------------------|
| 1940s | Stored-program computer                   | ENIAC, EDVAC                |
| 1960s | Instruction Set                           | IBM 360                     |
| 1970s | Pipeline, Vector Computer, Microprocessor | Cray-1, Intel 4004          |
| 1980s | RISC, Cache, Pipeline                     | MIPS R1000, POWER           |
| 1990s | SMP, CMP, Instruction-Level Parallelism   | MIPS R10000, PowerPC 604    |
| 2000s | SMT, Power Consumption, Multicore         | Intel i7, Power 6, ARM, GPU |
| 2020s | AI Accelerator. DSA                       | GPU, NPU                    |

