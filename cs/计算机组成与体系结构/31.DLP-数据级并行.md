# DLP-数据级并行

**数据级并行（Data-level parallelism，缩写为 DLP）采用的是SIMD架构**

DLP：将一个指令广播到多个处理单元上，但每个处理单元都有自己的数据。也就是说每个处理单元都有自己的数据存储器，但只有一个指令存储器和控制处理器，用来提取和分派指令。这样做的好处就是减轻的控制成本。

## 1 SIMD的特点 ##

* SIMD：仅限于少数应用场景（需要大量计算且所有处理执行相同工作的情况，通常在没有相同且独立的任务的情况下使用 MIMD 架构），只有可以被分解成很多个小问题（小问题之间要独立，可以不分先后顺序被相同的指令执行）的问题才可以用这种架构解决（很多超级计算机就是使用这架构设计出来的）。
* SIMD 设计简单，成本更低，速度更快。
* 由于是同步的，这种架构的算法非常好设计，分析和实现。
* 高级语言不好支持，基本上都是靠直接在C语言里嵌汇编来用。另外，用起来很不灵活，比如有时候我一部分位置要做计算，一部分位置不用做计算，这就很难整。

## 2 常见的SIMD体系结构变体 ##

**向量体系结构**

第一种变体的出现要比其他两个早30 年以上，它实际上就是以流水线形式来执行许多数据操作。与其他 SIMD 交体相比，这些向量体系結构更容易理解和编译，但过去一直认为它们对于微处理器来说太过品费了，这一看法直到最近才有所改变。这种体系结构的成本，一部分用在晶体管上，另一部分用于提供足够的 DRAM 带宽，因为它广泛依赖于缓存来满足传统微处理器的存储器性能要求。

**多媒体SIMD指令集扩展**

第二种 SIMD 变体借用 SIMD 名称来表示基本同时进行的并行数据操作，在今天支持多媒体应用程序的大多数指令集体系结构中都可 以找到这种变体。x86 体系结构的 SIMD 指令扩展是在 1996年以 MMoX（多媒体扩展）开始的，在接下来的 10年间出现了几个 SSE（流式 SIMD扩展）版本，一直发展到今天的 AVX（高级向量拉展）。为了使x86计算机达到最高计算速度，通常需要使用这些 SIMD 指令，特别是对于浮点程序。

> 注意，目前的CPU中一般的指令集就是SD（single data）的，而SSE、AVX这种指令就是MD（multi data）的。比如a，b和c都是相同大小的数组，要进行的计算是a的每一个元素与b的响应元素进行运算，结果放入c的对应元素中。如果没有SIMD，就需要写一个循环执行多遍来完成，而SIMD中 一条指令就可以并行地执行运算。

未使用SIMD：

```
vectorAdd(const float* a, const float* b, const float* c){
    for(int i=0; i<8; i++) {
        c[i] = a[i] + b[i];  //一条代码仅能操作2个单个值进行运算
    }                        //需要重复循环操作才能运算完整个数组间的加法
}
```

使用AVX：

```
__m256 vectorAdd(__m256 a, __m256 b, __m256 c) {
    return _mm256_add_ps(a,b); //一个方法可以同时操作整个数组进行运算 - 一步到位
}
```

**图形处理单元GPU**

SIMD 的第三种变体来自 GPU 社区，它的潜在性能要高于当今传统多核计算机的性能。尽管 GPU 的一些特征与向量体系结构相同，但它们有自己的一些独特特征，部分原因在于它们的发展生态系统，在GPU 的发展环境中，除了 GPU 及其图形存储器之外，还有系统处理器和系统存储器。事公上，为了辦识这些差别，GPU社区将这种体系结构称为异类。	
