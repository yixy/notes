# TLP-CacheCoherent #

Cache Coherence用于解决多处理器的本地Cache导致多个数据副本在Cache和存储器间不一致的问题。

## 1 什么是Coherent ##

**Cache Coherent（缓存一致性）**用于解决多处理器场景下各个处理器本地Cache导致的数据多副本问题：某处理器更新了存储器中的一个块，同一个块可能在其他处理器的Cache中还有过期副本。

实际上，Coherent不仅仅是针对cache的，可以用于描述和讨论解决任何存储器本地副本一致性问题。

## 2 Coherent定义形式1：SWMR不变性与数值不变性 ##

> 参考 A Primer on Memory Consistency and Cache Coherence

这里的coherence定义指定了不变性，关注的是不同core对一个内存位置的访问权限，以及拥有特定权限的core之间的数值传递。

**对每个内存位置，这个内存位置的生命周期被划分为了不同的时期(epoch)。每个时期内，要么是一个单独的core有read-write访问，（与前者互斥）要么是一些core（可能为0）有read-only访问。**

1. 单写者多读者（single-writer–multiple-reader， SWMR）不变性：对于任意给定的内存位置A，任意给定的时刻，只会存在一个单独的core可以改写A（这个core也可以读取A）或多个核只可以对A进行读取。因此，永远不会存在一个时间点，一个给定的内存位置既可以被一个core写入又可以同时被其它core读取或写入。
2. 数值不变性：指明了一个epoch开始时，一个内存位置的值和上一个对这个内存位置进行读写的epoch结束的时候的值相同。

除了SWMR不变性，一致性还要求给定内存地址的值能够被正确地传播。如在第一个只读时期里，多个core能够读到不同的值，那么这个系统也不是一致的。因此，一致性的定义必须对SWMR不变性增加数值不变性，数值不变性用来确定值是如何从一个时期（epoch）传播到下一个时期的。

SWMR不变性只需要在逻辑时间里维护，而非物理时间。这个细节使得许多优化方案看起来（但实际上并没有）违反了这个不变性。

在实践中，SWMR不变性基本就是：对任意的内存block，要么只有一个单独的写者，要么有多个读者。典型的系统中，不可能发生这种情况：一个core在写block的第一个字节，同时另外的core在写相同block里其它字节。

## 3 Coherent定义形式2：类似consistency的定义方法 ##

> 参考《量化》，该定义对于一致性协议的架构师来说不太直观。这些类似consistency的定义方法和上节节种展示的定义是一样合理的，并且它们能轻松地作为规范来使用，以便验证一个给定的协议是否实施了coherence。一个正确的一致性协议会满足这些定义的任意一个。

实际上还有另外一种类型的定义，由Hennessy和Patterson规定，包含了三个不变性。此定义聚焦在load和store上，和内存一致性模型（memory consistency model）如何指定load和store的顺序在体系架构上的可见顺序的概念类似。 （但两者不是一个层面的东西）

A memory system is coherent if：

1. A read by processor P to location X that follows a write by P to X,with no writes of X by another processor occurring between the write and the read by P, always returns the value written by P.（一个core对内存位置A的load操作所获取的值是前一次该core进行store的结果，除非另外一个core在其间进行了A的store操作；）
2. A read by a processor to location X that follows a write by another processor to X returns the written value if the read and write are sufficiently separated in time and no other writes to X occur between the two accesses.（对A的load操作所获取的值是另外一个core对A的store操作S的结果，如果S和这个load操作在时间上分开的足够多并且如果在S和load之间没有其它store操作的话；）
3. Writes to the same location are serialized; that is, two writes to the same location by any two processors are seen in the same order by all processors. For example, if the values 1 and then 2 are written to a location, processors can never read the value of the location as 2 and then later read it as 1.（对相同内存位置的store操作时串行的。这几个不变性集合是较为直观的，但在“时间上分开的足够多”这点上有点问题，不够精确。）

## 2 缓存一致性协议 ##

前面介绍的coherence不变性定义提供了一致性协议是如何工作的一些直觉性认知。大量的一致性协议，叫做"invalidate protocol"，被明确地设计用于维护这些不变性。如果core想过要读取一个内存位置，它会发送消息给其它core来获取内存位置的当前值，以此保证没有其它core保存着此位置上读写状态中的缓存拷贝。这些消息会结束任意活动状态的读写epoch，并且启动一个只读epoch。如果core想要写入一个内存位置，如果它还没有拥有一个合法的只读缓存拷贝，它会发送消息给其它core来获得内存位置的当前值，以此来保证没有其它core保存着此内存位置上只读或读写状态中的缓存拷贝。这些消息会结束任意活动的读写或只读epoch，并且启动一个新的读写epoch。

多处理器需要专门的硬件来实现Cache Coherence Protocol。缓存一致性协议有多种，但是你日常处理的大多数计算机设备使用的都属于“窥探（snooping）”协议，还有一种叫“基于目录的（directory-based）”协议，这种协议的延迟性较大，但是在拥有很多个处理器的系统中，它有更好的可扩展性。

**Bus Snooping，例如MESI**

*  Bus Snooping. 在体系结构中这种协议依赖一条总线传递信号，其他缓存监听信号并进行状态转换。典型的协议为MSI， MESI等，有write-invlaidation 和 write-update两种方式。通常认为Snooping由于总线带宽而具有扩展性存在问题。

“窥探”背后的基本思想是，所有内存传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线：缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁（arbitrate）：同一个指令周期中，只有一个缓存可以读写内存。窥探协议的思想是，缓存不仅仅在做内存传输的时候才和总线打交道，而是不停地在窥探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其他处理器都会得到通知，它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其他处理器马上就知道这块内存在它们自己的缓存中对应的段已经失效。

MSI协议：每个Cache Line上有几个标记位用来标志其处于Modified/Shared/Invalid中的某个状态，当处理器读写该Cache Line时，会根据其状态进行状态迁移并发送相应的协议消息以保持多副本数据的一致性。

* Exclusive：cache line只在当前cahe中，但是干净的（clean）--缓存数据同于主存数据。当别的缓存读取它时，状态变为shared；当前写数据时，变为modified状态。
* Modified：cache line只在当前cahe中，缓存行是脏的（dirty），与主存的值不同。如果别的CPU内核要读主存这块数据，该缓存行必须回写到主存，状态变为共享(S).
* Shared：缓存行也存在于其它缓存中且是干净的。缓存行可以在任意时刻抛弃。
* invalid：缓存行是无效的

**基于目录的协议**

当某一处理器修改了私有Cache中的数据后，并非每个处理器的Cache中都有该数据的副本。因此使用广播的方式并不是高效的。而且，并非所有的并行系统都支持广播。能否只通知那些含有被修改数据的副本的处理器？这就是基于目录的协议的思想。在基于目录的协议中，共享存储器维护一个目录，称为高速缓存目录，该目录中记载了申请了某一数据的所有处理器。这样，当数据被更新时，就根据目录的记载，向所有其Cache中包含该数据的处理器"点对点"地发送无效信息或更新后数据。目录可以是集中的，也可以分布于各个存储模块上。特别在某些系统内，存储器在逻辑上是共享的，但物理上是分布的。此时目录可以分布于各存储器内。目录也有多种形式，比如全映射目录，有限目录和链式目录。在全映射目录方案中，对于每个数据块，为每个处理机都设置一个标志位，这种目录比较庞大。在有限目录限方案中，限制同时含有同一数据块拷贝的Cache的数量。这样，当含有某一数据块的Cache数目已达限制数量，但仍有Cache申请该数据块时，就需要从已经含有该数据的Cache中 "驱逐" 出一个。因此有限目录需要相应的"驱逐策略"。在链式目录方案中，在处理器申请数据块的时将含有同一数据块的处理器用指针形成一个链表。通过该链表就可以找到所有含有该数据块的处理器。有限目录和链式目录更能适应处理器较多的场合，亦即有更好的扩展性。 
