# cache原理-时间空间的局部性 #

注意，本节包括后面几节cache原理是对缓存机制进行对探讨，这种探讨并不仅限于硬件，因为cache广泛被运用于计算机领域的各个场景中。

## 1 工作原理 ##

> CPU 与 低速IO设备速度的不一致采用中断机制（或者DMA）解决。

处理器和内存间的性能差异趋势导致了一种被称为**“存储墙”**的现象。为克服存储墙，设计者们引入了带有缓存（cache）的存储器体系层次（memory hierarchy），每层的延迟与容量都经过了权衡。缓存基于内存访问的局域性原理来缓解处理器与内存间的性能差距。但不幸的是，存在许多重要的工作负载会表现出不利的内存访问模式。这些模式会难住现代高速缓存层次结构中的简单更新策略（这些策略规定了指令和数据在缓存层次间移动的规则）。因此，对于在较高层缓存（L1、L2）中不存在的内存块，处理器往往需要花费大量时间获取它们。

cache的工作原理，主要基于两个认识，即**程序运行时数据具有时间局部性和空间局部性。**

* 时间局部性是指一个数据如果当前被使用到，那么接下去一段时间它很可能被再次用到；
* 空间局部性是指一个数据如果当前被使用到，那么接下去一段时间它周围的数据很可能也会被用到，比如数组。

基于局部性原理，设计出cache以便用较少的开销实现较的快存取速度，解决CPU与主存速度不一致的问题。cache硬件通常采用SRAM实现。

