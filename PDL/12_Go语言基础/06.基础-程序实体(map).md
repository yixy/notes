# 基础—程序实体(map) #

## 0. 底层实现原理

Golang的map是一个哈希表结构，其核心结构是一个buckets桶数组。

* buckets桶数组，数组长度为2^B，数组的每个元素是一个指针，指向一个桶链表（包含一个bucket桶和可能的多个溢出桶overflow bucket）。
* hash_binary(key) % B 为对应的桶数组索引（即用二进制hash值的低B位去匹配）
* 每个bucket桶存储8个kv对，桶内使用开放定址法（线性增1）解决冲突。如果超出8个kv对，则使用链地址法通过溢出桶bucket解决冲突。注意，具体实现中通过hash_binary(key)的高8位用于快速判定key是否相同，如果高8位相同，还需要使用key进行equals比较。

因为需要保证map读写操作都是O(1)，所以必须保证每个桶链表存储的kv数不能太多，桶链表长度不能太长。

* 支持桶链表个数动态扩容：如果桶内kv对总数/(2^B)大于6.5，则对桶链表个数进行翻倍扩容。注意，此时老桶中k要么还属于老桶，要么属于老桶索引+原数组长度。
* 支持对数据填充率低的桶链表长度进行动态调整：如果桶链表中溢出桶数量大于2^B次方时（B最大取15），保证桶链表个数不变的情况下，调整去除对应桶链表中的空洞。
* 采用渐进式扩容：当桶被实际操作时（发生写操作），由使用者负责完成数据迁移，避免因为一次性的全量迁移引发性能抖动。

## 1. Map基础 ##

map 存储键值对。map 的文法跟结构体文法相似，不过必须有键名。map 在使用之前必须用 make 而不是 new 来创建；值为 nil 的 map 是空的，并且不能直接赋值。

* Go 语言map的key类型不可以是函数类型、map类型、chan类型和切片类型。因为Go 语言的map类型其实是一个哈希表（hash table）的特定实现，因为hash值有可能相同，在这种情况下需要使用原来的key去做比较，所以map的key只能是任意定义了==与!=操作的类型。
* 注意，如果键的类型是接口类型或是数组类型，那么键的实际（元素）类型也不能是函数类型、map类型、chan类型和切片类型，否则在程序运行过程中会引发 panic。
* Map的value可以是一个函数
* 与Duck type接口方式一起实现单一方法对象的工厂模式
* Map本身是值传递，但是由于包含指针，有类似引用的副作用：

```go
//可以选择在创建时指定map的存储能力，分配合适空间，避免重复分配内存，提高性能
m=make (map[string] string,100)
//其他初始化方式
m:=map[int]int{1,2,3}
n:=map[int]string{}
//在 map m 中插入或修改一个元素：
m[key] = elem
//获得元素：
elem = m[key]
//删除元素：
delete(m, key)
//通过双赋值检测某个键存在。如果 key 在 m 中，`ok` 为 true 。否则， ok 为 `false`，并且 elem 是 map 的元素类型的零值。
elem, ok = m[key]
```

同样的，当从 map 中读取某个不存在的键时，结果是 map 的元素类型的零值。

内置函数len返回map拥有的key的数量。

for 循环的 range 格式可以对 slice 或者 map 进行迭代循环。

## 2. 底层代码实现

Go的map实际上是基于哈希表实现的。Go 语言运行时同时使用了多个数据结构组合表示哈希表，其中 runtime.hmap 是最核心的结构体：

```go
//runtime/map.go
type hmap struct {
	count     int       //表示当前哈希表中的元素数量，即kv对总数
	flags     uint8     //写保护标识位检测
	B         uint8     //2^B表示当前哈希表桶数组长度，也就是 len(buckets) == 2^B。因为哈希表中桶的数量都 2 的倍数，所以该字段会存储对数，便于进行位运算。
	noverflow uint16
	hash0     uint32    //hash0 是哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入；

	buckets    unsafe.Pointer   //buckets桶数组指针
	oldbuckets unsafe.Pointer   //oldbuckets 是哈希在扩容时用于保存之前 buckets 的字段，它的大小是当前 buckets 的一半；
	nevacuate  uintptr

	extra *mapextra //提前预先申请的溢出桶节点，供后续申请新桶节点时直接使用
}

type mapextra struct {
	overflow    *[]*bmap
	oldoverflow *[]*bmap
	nextOverflow *bmap
}
```

![](https://raw.githubusercontent.com/yixy4app/images/picgo/202406081053252.png)

如上图所示哈希表 runtime.hmap 的桶是 runtime.bmap。每一个 runtime.bmap 都能存储 8 个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用溢出桶存储存储数据。

上述两种不同的桶在内存中是连续存储的，我们在这里将它们分别称为正常桶和溢出桶，上图中黄色的 runtime.bmap 就是正常桶，绿色的 runtime.bmap 是溢出桶，溢出桶是在 Go 语言还使用 C 语言实现时使用的设计，由于它能够减少扩容的频率所以一直使用至今。

桶的结构体 runtime.bmap 在 Go 语言源代码中的定义只包含一个简单的 tophash 字段，tophash 存储了键的哈希的高 8 位，通过比较不同键的哈希的高 8 位可以减少访问键值对次数以提高性能：

```go
const bucketCnt = 8
type bmap struct {
	tophash [bucketCnt]uint8
}
```

在运行期间，runtime.bmap 结构体其实不止包含 tophash 字段，因为哈希表中可能存储不同类型的键值对，而且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导。runtime.bmap 中的其他字段在运行时也都是通过计算内存地址的方式访问的，所以它的定义中就不包含这些字段，不过我们能根据编译期间的 cmd/compile/internal/gc.bmap 函数重建它的结构：

```go
type bmap struct {
    topbits  [8]uint8
    keys     [8]keytype
    values   [8]valuetype
    pad      uintptr
    overflow uintptr
}
```

随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。

如果当前桶已经满了，哈希会调用 runtime.hmap.newoverflow 创建新桶或者使用 runtime.hmap 预先在 noverflow 中创建好的桶来保存数据，新创建的桶不仅会被追加到已有桶的末尾，还会增加哈希表的 noverflow 计数器。

### map查找

1. 写保护标识位检测（如果检测到已被设置则直接panic）
2. 计算hash（64位机是64位），找到hash低8位对应的bucket，先判是否正在扩容，如果扩容未完成则读旧的bucket，如果扩容完成则读新的迁移后的bucket。
3. 通过hash高8位tophash，遍历bucket中的8个键值对。

## 3. 遍历map时顺序是随机的

为了让使用者不依赖遍历map时key的有序性，map的key在遍历时故意被设计为顺序是随机的。

> 为什么map遍历key不能保障有序：因为在map扩容时，桶序号可能重分配，这样遍历时key顺序无法保障。

## 4. 非并发安全的Map & sync.Map & concurrent_map ##

### 非并发安全的原生Map

在Go 1.6之前， 内置的map类型是非goroutine安全的，即并发的读没有问题，并发的读写可能存在脏数据（注意，多读一写实际上也是可能有脏数据的）。自go 1.6之后， 程序检测到并发地读写map时会报错（fatal error: concurrent map writes），这在一些知名的开源库中都存在这个问题。

> 为什么map是非并发安全的：Go语言设计者认为map的大多数使用场景不涉及并发，如果map采用并发安全的实现方式将会大大降低在其他非并发场景的效率。

```go
//非安全的并发读写map，可能导致程序报错
package main

import (
    "fmt"
    "sync"
)
func main(){
    c := make(map[string]int)
    for j := 0; j < 1000000; j++ {
        c[fmt.Sprintf("%s", j)] = j
    }
    var w sync.WaitGroup

    for i := 0; i < 100; i++ {
        go func() {
            w.Add(1)
            for j := 0; j < 1000000; j++ {
                fmt.Println(c[fmt.Sprintf("%s", j)])
                //c[fmt.Sprintf("%s",j)]=j
            }
            w.Done()
        }()
    }

    for j := 0; j < 1000000; j++ {
        //fmt.Println(c[fmt.Sprintf("%s", j)])
        c[fmt.Sprintf("%s",j)]=j
    }
    w.Wait()
}
```

### 简单的解决方案

所以go 1.9之前的解决方案是额外绑定一个锁，封装成一个新的struct或者单独使用锁都可以。但是采用内置的Map加读写锁的机制，会lock整个map所以性能不是很好。

```go
package main
import (
    "fmt"
    "sync"
)
type syncMap struct {
    items map[string]int
    sync.RWMutex
}
func main() {
    c := &syncMap{items: make(map[string]int)}
    var w sync.WaitGroup
    for i := 0; i < 100; i++ {
        go func() {
            w.Add(1)
            for j := 0; j < 1000000; j++ {
                //读写锁
                c.Lock()
                c.items[fmt.Sprintf("%d", j)] = j
                c.Unlock()
            }
            w.Done()
        }()
    }
    w.Wait()
}
//读锁
//counter.RLock()
//counter.RUnlock()
```

以上方案存在的问题：

* 读写锁的粒度太大了，保护了整个 map 的访问。写操作是阻塞的，此时其他任何读操作都无法进行。
* 如果内部的 map 存储了很多 key，GC 的时候就需要扫描很久。

### sync.Map

golang1.9开始，提供sync.Map以支持并发安全的map。sync.Map采用了空间换时间的方案，并且采用指针的方式间接实现值的映射，所以存储空间会较built-in map大。sync.Map具体的实现方式是维护两块空间readonly和dirty，写的时候写到dirty区，读的时候先读readonly（无锁），如果miss再读dirty（加锁）并且将其移动到readonly。可以看出这种实现适合读多写少，且Key相对稳定的场景。经验值是适用于读写比9:1的（读90%），写更多的情况下性能下降很多。

```go
// go 中的 sync.Map
type Map struct {
        // 互斥锁，保护 dirty
	mu Mutex

	// readonly 原子容器，真实类型 readonly，里面包含了一个通过只读操作访问的 map，类型也是 map[any]*entry
	read atomic.Value // readOnly

	// 拥有全量数据的读写 map，被 mu 保护
	dirty map[any]*entry

	// 操作时 readonly 发生 miss 次数，累计达到一定次数时会更新 readonly
	misses int
}

// readOnly is an immutable struct stored atomically in the Map.read field.
type readOnly struct {
        // 只读 map，完全无锁化访问
	m       map[any]*entry
        // readonly 相比 dirty 是否存在数据缺失
	amended bool // true if the dirty map contains some key not in m.
}

// 硬删除状态
var expunged = unsafe.Pointer(new(any))

// 存储一个值的指针容器
type entry struct {
	p unsafe.Pointer // *interface{}
}

// Store sets the value for a key.
func (m *Map) Store(key, value any) {
	// ...
}

func (m *Map) Load(key any) (value any, ok bool) {
	// ...
}

// Delete deletes the value for a key.
func (m *Map) Delete(key any) {
	// ...
}

func (m *Map) Range(f func(key, value any) bool) {
	// ...
}
```

* 空间冗余：sync.Map 基于以空间换时间的思路设计实现，在物理意义上存在两个独立 map，分别是 readonly.m 和 dirty；
* 读写分离：readonly.m 主要面向无锁访问的只读操作， 而 dirty 则面向加锁访问的读写操作. 因此读操作优先无锁化访问 readonly，当击穿 readonly 时（readonly 数据 miss），才加锁访问 dirty 进行兜底. 通过这种读写分离的机制，把更多读操作引导到 readonly 模块减少加锁互斥的频率，提高整体访问性能
* 广义读操作：两个 map 真正的实现类型是基于 key-entry 的形式，而 entry 是存储 value 指针的容器. 因此只有在插入一组不存在 key-entry 时，才是严格意义上的写操作；其他针对已存在的 key-entry 的更新操作，都是广义上的读操作，可以通过读取出 key 对应 entry，再基于 CAS（compare-and-swap）操作完成内容更新；
* 延迟删除：删除 key-entry 时，不是立即从 map 中删除 key，而是尝试读到 key 对应 entry，然后通过 cas 将 entry 标记为软删除态（nill）. 后续在逆向迁移流程统一执行实际删除操作. 因此针对已存在的 key-entry 的删除操作，也是广义上的读操作.
* 正向迁移 O(1)：由于 readonly 是只读模式，所以新增插入数据会作用到 dirty 中，导致 readonly 数据仅是 dirty 的子集. sync.Map 中通过 misses 计数器记录 readonly 被读操作击穿的次数，以此反映存在缺失数据的比重，当比重达到阈值时，会将 dirty 中的全量数据覆盖到 readonly 中补齐其缺失的部分，此为正向迁移流程(missLocked)。
* 逆向迁移 O(n)：由于sync.Map 中的延迟删除机制，被置为删除态的 entry 需要有额外的回收时机. 在执行完正向迁移后，会短暂地将 dirty 置空，并在随后到来的下一次击穿 readonly 的插入行为中，执行逆向迁移流程（dirtyLocked）——遍历 readonly，过滤所有删除态 entry，并将仍存在的 entry 拷贝到 dirty 中. （如此一来，在下一次因正向迁移而使用 dirty 覆盖 readonly 时，这部分删除态 entry 就会丢失引用，实现事实意义上的回收）。
* 软硬删除：sync.Map 的删除行为是在逻辑意义上将 entry 更新为软删除态（nil），反之，如果想要恢复一笔已删除的 key-entry，也只需要将 entry 状态由软删除态（nil）恢复成正常态即可，这样都属于广义上的读行为，是无需加锁. 然而，如果一个 entry 处于硬删除态（expunged），那么它就是不可恢复的，必须通过加锁后执行插入操作来补齐对应数据。

sync.Map 不是银弹，它只是在特定场景中有着比较不俗的表现：

* 读多写少：相较于不断插入新 key，sync.Map 更支持的访问模式是，一个给定 key 被写入后，会存在多次读访问行为加以复用. 这里的读访问是广义上的，同时包括更新和删除操作.

与此同时，我们也需要明确 sync.Map 中存在的几个局限性：

* 不适用于插入写操作：在插入写操作中，sync.Map 退化为基于互斥锁 mutex + dirty map 实现的基础结构，此时不存在性能优势，其复杂的结构设计反而徒增成本；
* 存在性能抖动：由于延迟删除机制的存在，在 sync.Map 执行到逆向迁移 dirtyLocked 流程时，会对 readonly 进行线性遍历，这次操作是 O(N) 的，相较于其他 O(1) 的访问操作，存在明显的性能短板
* 不利于序列化：由于底层复杂的结构设计，sync.Map 不像 go 中普通 map 一样，天然契合序列化/反序列化能力
* 不利于数量统计：由于延迟删除机制的存在，sync.Map 无法直接通过 entry 个数反映出 key-value 数量，因为其中可能存在处于删除态的 entry

### concurrent_map

concurrent_map，1:1对写场景下比sync.Map性能更好。

区别于整个map+读写锁的方式，concurrent_map（`https://github.com/easierway/concurrent_map`）采用了将map分区然后加锁的方式，降低了锁冲突的概率。
