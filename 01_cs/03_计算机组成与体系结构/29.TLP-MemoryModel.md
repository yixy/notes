# TLP-MemoryConsistencyModel

Memory Model是多处理器和编译器优化导致存储器操作被多个处理器观察到的顺序不一致的问题。

## 1 Memory Consistency Model是什么 ##

**Memory Model(Memory Consistency/Memory Consistency Model)：通过规范加载和存储（内存的读和写）来定义正确的共享内存行为，它不涉及cache和cache coherence相关内容。内存模型指定了使用共享内存的多线程程序执行中所允许的行为，注意，多个正确的行为都是被允许的，因此内存一致性模型并非是显而易见地容易理解。**

对一个使用特定输入数据，正在执行的多线程程序来说，内存模型指定了动态加载（loads）动作可以返回什么值，以及内存最终变化到的各种可能的状态。Consistency是系统和程序员之间的规范，它规定了在一个共享存储器的多线程程序中的存储器访问应该表现出怎样的行为。这个规范影响了系统的性能，因为**它决定了多处理器/编译器能应用哪些优化；也影响了可编程性(Programmability)**，因为多线程程序的正确性取决于Memory Model，从而约束了程序员的编程方式。

> tips：内存模型 和 内存分配 或者 内存回收 通常容易弄混淆，**内存模型这个名词就是来解决多核心编程而提出来的。memory model 是专有名词，有特定含义。**技术交流要有共识，否则就是鸡同鸭讲，不能按照字面意思简单理解一下，然后固执地认为自己理解的意思，而不顾行业内大家共识的含义。

> 参考wiki百科上相关的概念如下：Memory model (programming): In computing, a memory model describes the interactions of threads through memory and their shared use of the data.

## 2 为什么需要Memory model ##

**导致指令执行顺序变动的编译器/硬件优化**：

* 降低缓存缺失率的编译器优化：循环交换、分块等处理
* ILP的静态调度（编译器循环展开）和动态调度（硬件循环展开）
* ILP的多发射技术（超标量流水线）

```
//下面这个例子，由于指令重排或乱序执行，r可能为0
//start: A=0, B=0

//Thread 1
A=1
B=1

//Thread 2
while B=0 {}
Load r=A
```

**写原子性(Store Atomicity)问题：处理器的写操作是否同时被所有处理器看到。 **

```
//下面这个例子，由于指令重排或乱序执行，r2可能为0
//start: A=0, B=0

//  thread 0                thread 1                thread 2
//-----------------------------------------------------------------
    store A, 1      
                            loop:
                            load %r0, A
                            beq %r0, 0, loop
                            BARRIER
                            store B, 1
                                                    loop:
                                                    load %r1, B
                                                    beq %r1, 0, loop
                                                    BARRIER
                                                    load %r2, A
```

运行在单处理器(且没有DMA设备等)上的单线程程序无需考虑以上内容，因为处理器/编译器的优化都保证对程序员透明，即程序看起来像是按自然顺序(Program Order)执行的。然而在多线程程序中，编译器和多处理器并无手段自动发现多个线程间的协作关系，使得那些可能改变存储器访问顺序和次数的优化，同时对多个线程透明。

没有程序员的帮助，要保持多线程程序的正确性，系统只能禁用这些作用在共享存储器上的优化，而这将严重损害性能。为最大限度保留编译器和多处理器的优化能力，同时使多线程程序的执行结果是可预测的，系统需要程序员的帮助。最后的方案是，系统提供所谓Memory Model的规范，程序员通过规范中同步设施(各种内存屏障(Memory Barrier)和Atomic指令)来标记多个线程间的协作关系，使得不仅是单线程，系统的优化对多线程程序也将透明。

## 3 Memory Model的构成属性 ##

Memory Model主要规定不同地址上的读写操作在其他处理器看来会否乱序，以及，一个写操作是否同时被其他处理器观察到：

**Memory Ordering**

* Load-Load Order：不同地址上的读操作会否乱序
* Load-Store Order：读操作和后面另一个地址上的写操作会否乱序
* Store-Load Order：写操作和后面的读操作会否乱序
* Store-Store Order：不同地址上的写操作会否乱序
* Dependent Loads Order：当第二条读操作的地址取决于前一条读操作的结果时，会否乱序

**写原子性(Store Atomicity)**：处理器的写操作是否同时被所有处理器看到。根据写操作的同时性，从弱到强排序：

* Load Other's Store Early && Non-Causality：允许写操作被自己及个别其他处理器先看到，不支持Causality。写序列可能以不同顺序被多个处理器观察到
* Load Other's Store Early && Causality：允许写操作被自己及个别其他处理器先看到，支持Causality
* Load Own Store Early：只允许写操作被自己先看到。写序列以相同顺序被多个处理器观察到
* Atomic Store：所有处理器同时看到写操作

## 4 Consistency 与 Coherence 区别：纬度不同 ##

**Cache Coherence是多处理器的本地Cache导致多个数据副本在Cache和存储器间不一致的问题，Memory Model是多处理器和编译器优化导致存储器操作被多个处理器观察到的顺序不一致的问题。**

coherence不适用于体系架构（即coherence不是体系架构级可见的）。严格来讲，系统可以是非coherence但仍然是正确的，只要它遵守特定的内存一致性模型（memory consistency model）。虽然这个问题可能看起来只是单纯的好奇心引发的（即很难想象有一个实际的系统是consistent但不是coherent的），它却有一个很重要的推论：**内存一致性模型没有强加任何显式的约束给coherence，或是实现coherence的协议。尽管如此，许多consistency模型实现依赖于某些通用的coherence属性来实现正确性。**

此外，Memory Consistency和Cache Coherernce还有这些明显区别：

* 前者的研究对象是多个地址，后者的研究对象是单个Cache Line
* 就正确性而言，前者对程序员可见，后者对程序员透明，尽管后者影响性能
* Memory Model可以实现在只有coherent Cache甚至没有Cache的多处理器系统上

一般讨论Memory Model中的读写乱序，是指对任意地址读写的乱序；但从实现层面讲，由于系统必须保证乱序对执行读写的线程透明，而相同地址的读写存在数据相关Data Dependence，所以系统实际上只能对不同地址的读写进行乱序。（所以也有说法认为：Coherence and consistency are complementary: Coherence defines the behavior of reads and writes to the same memory location, while consistency defines the behavior of reads and writes with respect to accesses to other memory locations.）

注意，看起来cache一致性（coherence）定义了共享内存的行为。但其实并没有，理由有三：

* cache coherence的目的是让多核系统中的cache如单核系统中的cache一样变得对外不可见。然而，一旦cache变得不可见，还有哪些行为仍然存在？
* coherence典型来说一次处理一个cache block，并且对于访问多个cache block的交互上没有任何干预。真实的程序会访问跨越多个cache block的变量。
* 实现一个不带coherence，甚至是不带cache的内存系统是可能的。

尽管coherence不是必需的，大多数共享内存系统实现内存一致性模型（memory consistency model）时都带有一致性cache（coherent cache）。

## 5 最严格并且最直观的内存模型SC：Sequential consistency ##

**Sequential consistency：SC模型表述了一个多线程的运行过程应该看起来像是每个线程的顺序执行的交织执行过程，就好像这些线程在一个单核处理器上分时复用一样。**执行的结果看起来就是全部处理器（核）按照某种顺序执行，并且每个独立的处理器（核）的操作按照程序指定的顺序出现即可。这个总的操作顺序称为**内存顺序（memory order），内存顺序并不是唯一的，在SC中，内存顺序不违背每个core的程序顺序**。

SC规定系统执行所有线程对全部内存位置的load和store操作必须看起来是按照一个总的顺序(total order)进行的，这个总的顺序会考虑每个线程的程序顺序。每个load操作会获取到总顺序中最近一次store操作的值。coherence的定义如果用SC的定义来类比，就是一个一致性系统执行所有线程对单个内存位置的load和store操作必须看起来是按照一个总的顺序进行的，这个总的顺序会考虑每个线程的程序顺序。这个定义突出了coherence和consistency的一个重要的区别：coherence是基于单个内存位置的，而consistency是指定全部内存位置的。（snooping系统会确保coherence的总顺序是跨越所有block的，尽管coherence仅要求对单个独立的block的coherence请求形成一个总顺序。这种看似做过了的情况是snooping协议可以用来支持一致性模型consistency model要求的原因)。

**SC允许两种朴素的实现方案**，这些方案使得理解哪些是SC所允许的执行过程变得更容易。

* 多任务的单处理器（The Multitasking Uniprocessor）：首先，实现者能够为多线程用户级软件实现SC，通过在一个单独的顺序核上执行所有线程（单处理器）来实现。线程T1的指令执行在core C1上，直到进行上下文切换到线程T1，以此类推。在上下文切换时，任意的待决（pending）的内存操作在切换到新的线程之前必须做完。一个检视动作显示出所有SC规则都被遵守了。
* The Switch：实现者能够使用一组core，一个单独的switch以及内存来实现SC。假定每个core都按照自身的程序顺序在一个时间点发送一个内存操作给switch。每个core能够使用任何的优化手段，这些优化不影响它给switch所呈现的顺序。例如，带分支预测的简单的5级顺序流水线能够被使用。接下来假定switch选择了一个core，允许内存完全满足load或store操作的要求，只要请求一直存在，这个过程就一直被重复。switch可以通过任意的方法（例如随机）来选择core，此方法不能饿死带有ready的请求的core。这种方案通过结构可操作地实现了SC。

对于这两种实现方案，好消息是，它们提供了可运作的的模型，模型定义了 (1)允许的SC execution以及(2)SC实现方案的“黄金标准”。switch方式的实现也可作为一个有利的证明，证明SC可以不用cache或coherence也能实现。当然坏消息是，这两种实现的性能不会随着core的增加而提升，因为在第一种场景里，存在单核的顺序执行瓶颈，第二个场景里受到单个switch/memory的影响，性能也无法提高。这些瓶颈误导了一些人错误地认为SC阻止了真正的并发执行，但其实并没有，我们后面会看到原因。

**带cache一致性(coherence)的基础SC实现**

cache一致性使得能够完全并发执行非冲突（non-confilicting）的load和store操作的SC实现变得更加便利（两个操作冲突是指：如果它们操作相同地址并且至少有一个操作是store）。还有就是，创建这样的系统在概念上很简单。在这里，我们将coherence基本看作一个黑盒子，这个黑盒子实现了之前提到的coherence单写者-多读者不变性（SWMR）。

实际上，我们在之前switch模型基础上将switch/memory替换为一个cache一致的（cache-coherent）内存系统黑盒子。每个core都按照自己的程序顺序一次发送一个内存请求到这个cache一致的内存系统。这个内存系统在开始针对相同core的下一个请求前会先处理掉系统种的每一个请求。

* 完全利用了cache的延迟和带宽优点
* 和它所使用的cache coherence协议有相同的可伸缩性
* 解耦了实现coherence和实现core的复杂性

大部分真实的core在实现上比前面介绍的基础的带cache coherence的SC实现方案要更加复杂。为了改进性能以及容忍内存访问延迟，core会带有一些特性如预取，预测执行以及多线程。

## 6 TSO内存模型/x86内存模型 ##

一个被广泛实现的内存一致性模型是**TSO（total store order）**。TSO被用在SPARC的实现中，更重要的是TSO看起来和广泛使用的x86架构的内存模型是匹配的。该模型是受到使用基于FIFO的write buffer（在写结果到cache前用来保存已提交存储操作的结果）的需求所驱动的。这个优化破坏了SC模型，但却保证了足够的性能提升来促使体系架构去定义TSO。

> 我们**推测x86内存模型和TSO是等价的（针对普通的可缓存内存以及普通指令）**。AMD和Intel公开地定义了x86的内存模型，使用了Sewell等人总结了一些例子和文章。所有例子都遵循TSO，并且所有文章看起来也和TSO保持一致。当然除非有公开的、正式的x86内存模型描述文档出现才能证明这个等价的推测。如果有显示x86执行有不被TSO允许，x86不允许的TSO执行，或两者都存在的反例，那么这个等价的推测就不成立。

处理器核长期以来使用write(store) buffer来保存已提交的（committed, retired）store操作，直到内存系统的剩余部分能够处理这些store为止。当store操作提交时，store进入到write buffer；当要被写入的block在cache中处于read-write coherence状态时，store离开write buffer。我们能明显地看到，一个store操作能够在cache取得待写入block的read-write coherence权限前进入到write buffer；write buffer因此隐藏了服务store miss的延迟。因为store操作很常见，有能力去避免它们中绝大部分的拖延是很有益处的。另外，不去拖延core看起来是很合理的，因为core不需要关注操作内存本身的过程，store操作试图更新内存而不是更新core状态。

对一个单核处理器而言，write buffer能够被做成体系架构上不可见的，通过保证一个对地址A的load操作返回最近一次对A的store操作的值来实现，即便是有一个或多个对A的store操作都在write buffer中。典型的做法是：要么通过旁路(bypassing)方式获取最近一次的（most recent）对A的store操作的值，这里的“最近”是由程序顺序确定；要么是通过拖延A的load操作来实现，前提是write buffer中有对A的store操作。

当创建一个多核处理器时，很自然会想到它会使用多个core，每个core有自己的bypassing write buffer并且假设这些write buffer仍是体系架构上不可见的。

一种对于write buffer可见于体系架构的回应方式是关掉write buffer，但制造商不愿意去这样做，因为会造成潜在的性能冲击。另外一种选项是使用激进的，带预测的SC实现方案来让write buffer不可见，但这样做增加了复杂性并会消耗掉额外的功率去检测违反情况和处理错误预测的情况。

SPARC和X86所选择的方式是不用SC，采用了一种内存一致性模型，该模型允许每个core简单地使用一个先入先出（FIFO）的write buffer。这个新的模型TSO的表现会让一些人感到惊讶，但它在结果上，对于大多数编程习惯语来说和SC的表现是相似的并且在所有场景下都是良好定义的。**sparc-TSO 和 x86 拥有相对较强的处理器内存模型，它们仅允许对写 - 读操作做重排序（因为它们都使用了写缓冲区）。**


TSO（Total Store Order）内存模型，也被称为 x86 内存模型，是一种保证某些类型的内存操作顺序的内存模型。x86 架构的 CPU 使用了这种内存模型。

在 TSO 内存模型中，每个处理器都有一个存储缓冲（store buffer）或者写缓冲（write buffer），以及一个加载缓冲（load buffer）。当处理器执行存储操作时，该操作被放入存储缓冲中，并可能在稍后的某个时间点提交到内存中。当处理器执行加载操作时，它首先查看存储缓冲中是否有相应的存储操作；如果有，它就直接从存储缓冲中获取数据，否则它就从内存中加载数据。

这种设置保证了在单个处理器上的存储操作总是以它们发生的顺序被看到，即“存储顺序”（Store Order）。然而，由于存储缓冲的存在，不同处理器上的存储操作可能以不同的顺序被看到，这可能导致在多处理器系统中出现一些复杂的行为。

除此之外，TSO 还保证了以下性质：

对于单个处理器，加载操作不会重排序到前面的存储操作之前（Load→Store）。
对于单个处理器，存储操作不会重排序到前面的任何操作之前（Store→Load/Store）。
对于单个处理器，加载操作可以重排序到前面的加载操作之前（Load→Load），这也是为什么加载缓冲存在的原因。
因此，TSO 内存模型为开发者提供了一种相对简单、易于理解的模型，但同时也需要开发者理解和处理多处理器环境中的内存一致性问题。

## 7 更松散（relaxed/weak）的模型 ##

SC实现方案是TSO的真子集。所有SC执行都是TSO执行，某些TSO执行是SC执行，某些TSO执行不是SC执行。

还存在比TSO更“松散”（relaxed）或叫“弱”(weak)的内存一致性模型。

更加松散（弱）的内存一致性模型的主要好处是强制要求的排序约束更少，允许更多的硬件和软件（编译器和运行时系统）优化，能够获得更高的性能。主要的缺点是松散的模型必须规定好什么时候排序是被“要求”的，还要提供给程序员或底层软件一些机制用于和实现沟通这种顺序，如果制造商在一个独立的松散模型上没有遵守这些规则，则会牺牲可移植性。

## 8 再议Memory Model模型的取舍 ##

1）多处理器和编译器对Memory Model的诉求

对多处理器而言，允许所有存储器操作的乱序可以提供最多的优化机会，哪怕其中一些顺序它能高效实现；允许部分处理器先观察到写结果，能够减少在Cache Coherence Protocol上阻塞的时间。类似的，编译器优化也期望能够自由地对代码做变换，只要这种变换不改变单线程执行的结果。故，多处理器和编译器都倾向于提供一种允许任意乱序、没有原子写要求的Memory Model

2）程序员对Memory Model的诉求

程序员需要的Memory Model是，运行在多处理器系统上的共享内存多线程程序，看起来就像是并行或交错的多个顺序执行的线程，没有任何乱序、写操作也立即全局可见，同时每个线程和单线程程序运行得一样块，多线程的整个程序性能随处理器个数伸缩

3）如何调和二者的矛盾

理想的Memory Model，能够尽量满足上面系统和程序员的诉求：允许各种乱序、非原子写，但只要程序员按一定的模式来组织程序、协调多个线程的通信，那这些混乱都是透明的。

实际上Memory Mode一般分为两层：汇编语言中的Memory Model由具体多处理器规定和实现，不可移植；在硬件内存模型之上，还存在着为高级编程语言设计的内存模型，高级语言中的Memory Model由高级语言标准来规定，由编译器和目标多处理器共同实现，可移植。（比如Java屏蔽来各种硬件和OS内存访问差异，实现了Java程序能在各种硬件平台下都能按照预期方式运行。设计编程语言级别的内存模型，这是为了在使用相应编程语言的时也能拥有一个一致性的内存视图。）

互斥锁(Exclusive Lock)是被最广泛支持的同步机制，编译器和多处理器会确保基于锁同步的多线程程序看起来就像是有多个同时执行的顺序线程。而一旦离开锁的庇护，程序员要么直面各种优化作用下的混乱世界，要么和实现同步原语(Synchronization Primitives)的系统工程师站在同一起跑线，捡起Memory Model这个更细粒度、更微妙的武器，在乱序优化的多线程世界中重建秩序。

**Linux Kernel和高级语言标准都定义了自己的Memory Model，其中有专门的同步操作用于线程间协作。编译器负责将这个抽象的Memory Model映射到目标多处理器上，如果多处理器自己的Memory Model相对更强，那么上层Memory Model的同步操作可能退化成普通的存储器访问；如果目标多处理器的Memory Model相对更弱，则部分上层同步操作可能生成处理器提供的Barrier或Atomic指令来强制顺序和写原子性。**

