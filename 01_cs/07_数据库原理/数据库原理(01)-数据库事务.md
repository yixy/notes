# 数据库原理(01)-数据库事务 #

## 1. ACID ##

数据库事务有严格的定义，它必须同时满足4个特性：原子性（Atomic）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability），简称为ACID。

* 原子性（Atomic）：表示组成一个事务的多个数据库操作是一个不可分割的原子单元，只有所有的操作执行成功，整个事务才提交。事务中的任何一个数据库操作失败，已经执行的任何操作都必须撤销，让数据库返回到初始状态。
* 一致性（Consistency）：事务操作成功后，数据库所处的状态和它的业务规则是一致的，即数据不会被破坏。如从A账户转账100元到B账户，不管操作成功与否，A账户和B账户的存款总额是不变的。
* 隔离性（Isolation）：在并发数据操作时，不同的事务拥有各自的数据空间，它们的操作不会对对方产生干扰。准确地说，并非要求做到完全无干扰。数据库规定了多种事务隔离级别，不同的隔离级别对应不同的干扰程度，隔离级别越高，数据一致性越好，但并发性越弱。
* 持久性（Durability）：一旦食物提交成功后，事务中所有的数据操作都必须被持久化到数据库中。即使在提交事务后，数据库马上崩溃，在数据库重启时，也必须保证能够通过某种机制恢复。

在这些事务特性中，数据“一致性”是最终目标，其他特性都是为达到这个目标而采取的措施、要求或手段。

数据库管理系统一般采用重做日志来保证原子性、一致性和持久性。重做日志文件记录了数据库变化的每一个动作，数据库在一个事务中执行一部分操作发生错误退出，数据库即可根据重做日志撤销已经执行的操作。此外，对于已经提交的事务，即使数据库崩溃，在重启数据库时也能够根据日志对尚未持久化的数据进行相应的重执行操作。

数据库管理系统通常采用数据库锁机制保证事务的隔离性。当多个事务试图对相同的数据进行操作时，只有持锁事务才能操作数据，直到前一个事务完成后，后面的事务才有机会对数据进行操作。Oracle数据库还使用了数据版本的机制，在回滚段为数据的每个变化都保存一个版本，使数据的更改不影响数据的读取。

## 2. 数据并发的问题 ##

数据并发问题可以分为5类，包括3类数据读问题（脏读、不可重复读和幻象读）及2类数据更新问题（第一类丢失更新和第二类丢失更新）。

* 脏读（dirty read）：A事务读取B事务尚未提交的更改数据，并在这个数据的基础上进行操作。如果恰巧B事务回滚，那么A事务读到的数据是不被承认的。
* 不可重复读（unrepeatable read）：A事务读取了已经提交的B事务的更改数据（update 或 delete），和B事务提交之前时间点的数据不一致。
* 幻象读（phantom read）：A事务读取B事务提交的新增数据。一般发生在计算统计数据的事务中。

注意，幻象读和不可重复读诗两个容易混淆的概念，前者是指读取到了其他已经提交事务的新增数据，而后者是指读到了已经提交事务的更改或删除数据。为了避免这两种情况，采取的策略是不同的，防止不可重复读只需要对操作的数据添加行级锁，而防止幻象读往往需要添加表级锁（Oralce使用多版本数据的方式实现）。

* 第一类数据丢失更新：A事务撤销时，把已经提交的B事务的更新数据覆盖了。
* 第二类数据丢失更新：A事务覆盖B事务已经提交的数据，造成B事务所做的操作丢失了。

## 3. 数据库锁机制 ##

数据库的锁机制用于解决数据并发的问题。

按锁定的对象不同，一般可以分为表锁定和行锁定。

* 表锁定：对整张表进行锁定。
* 行锁定：对表中的特定行进行锁定。

按并发事务锁定的关系上看，可以分为共享锁定和独占锁定。

* 共享锁定：共享锁会防止独占锁定，但允许其他的共享锁定。
* 独占锁定：独占锁既防止其他独占锁定，也防止其他共享锁定。

为了更改数据，数据库必须在进行更改的行上施加行锁定。

数据库为用户提供了锁的DML操作方式，但是直接使用锁管理是非常麻烦的，因此数据库为用户提供了自动锁机制。只要用户指定会话的事务隔离级别，数据库就会分析事务中的SQL语句，然后自动为事务操作的数据资源添加合适的锁。ANSI/ISO SQL92标准定义了4个等级的事务隔离级别：

* READ UNCOMMITED：允许脏读，允许不可重复读，允许幻象读，不允许第一类丢失更新，允许第二类丢失更新。
* READ COMMITTED：不允许脏读，允许不可重复读，允许幻象读，不允许第一类丢失更新，允许第二类丢失更新。
* REPEATABLE READ：不允许脏读，不允许不可重复读，允许幻象读，不允许第一类丢失更新，不允许第二类丢失更新。
* SERIALIZABLE：不允许脏读，不允许不可重复读，不允许幻象读，不允许第一类丢失更新，不允许第二类丢失更新。
